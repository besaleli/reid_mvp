{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb69204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "conn = duckdb.connect(\"data/data.db\")\n",
    "\n",
    "query = \"\"\"\n",
    "select\n",
    "    f.video_frame_index,\n",
    "    f.timestamp_ms,\n",
    "    d.id,\n",
    "    r.cluster_id,\n",
    "    d.osnet_embedding,\n",
    "    d.clip_embedding,\n",
    "from intravideo_object_ids r\n",
    "left join detection d on d.id=r.detection_id\n",
    "left join frame f on f.id=d.frame_id\n",
    "left join video v on v.id=f.video_id\n",
    "where\n",
    "    v.filepath ilike '%video_1%'\n",
    "    and not r.is_bad_frame\n",
    "\"\"\"\n",
    "\n",
    "df = conn.sql(query).df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ccef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ruptures as rpt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from scipy.ndimage import binary_opening, binary_closing\n",
    "\n",
    "max_frame = df['video_frame_index'].max()\n",
    "min_frame = df['video_frame_index'].min()\n",
    "n_frames = max_frame + 1\n",
    "\n",
    "clusters = df['cluster_id'].unique()\n",
    "\n",
    "cluster_signals = {\n",
    "    int(cluster_id): np.zeros(n_frames, dtype=np.uint8) for cluster_id in clusters\n",
    "}\n",
    "\n",
    "cluster_breakpoints = {}\n",
    "bucket_labels = {}\n",
    "\n",
    "for cluster_id, group in df.groupby(\"cluster_id\"):\n",
    "    cluster_signals[cluster_id][group[\"video_frame_index\"].values] = 1\n",
    "\n",
    "    signal = cluster_signals[cluster_id]\n",
    "    \n",
    "    # smooth flickers in signal signal\n",
    "    smoothed = binary_closing(signal, structure=np.ones(10))\n",
    "    smoothed = binary_opening(smoothed, structure=np.ones(10))\n",
    "    \n",
    "\n",
    "    algo = rpt.Pelt(model=\"l2\", min_size=100).fit(smoothed)\n",
    "    breakpoints = algo.predict(pen=20)\n",
    "    \n",
    "    min_length = 150\n",
    "    filtered_cps = [cp for i, cp in enumerate(breakpoints)\n",
    "                if i == 0 or (cp - breakpoints[i-1]) > min_length]\n",
    "    cluster_breakpoints[cluster_id] = breakpoints\n",
    "    print(breakpoints)\n",
    "    \n",
    "    labels = np.full_like(signal, fill_value=-1, dtype=np.int8)  # or use None or np.nan if preferred\n",
    "    bucket = 0\n",
    "    bp_idx = 0\n",
    "\n",
    "    prev = 0\n",
    "    curr = 0\n",
    "    curr_label = 0\n",
    "    \n",
    "    for breakpoint in breakpoints:\n",
    "        curr = breakpoint\n",
    "        \n",
    "        labels[prev:curr] = curr_label\n",
    "        \n",
    "        prev = breakpoint\n",
    "        curr_label += 1\n",
    "    \n",
    "    bucket_labels[cluster_id] = labels[labels != -1]\n",
    "\n",
    "PERSON_ID = 0\n",
    "\n",
    "print(pd.Series(bucket_labels[PERSON_ID]).value_counts())\n",
    "rpt.display(cluster_signals[PERSON_ID], cluster_breakpoints[PERSON_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e43cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "person_1 = df[df['cluster_id'] == PERSON_ID]\n",
    "person_1 = person_1.merge(\n",
    "    pd.DataFrame({\n",
    "        \"appearance_bucket\": bucket_labels[PERSON_ID],\n",
    "        \"signal\": cluster_signals[PERSON_ID]\n",
    "    }),\n",
    "    how=\"left\",\n",
    "    left_on=\"video_frame_index\",\n",
    "    right_index=True\n",
    ")\n",
    "# get interarrival times\n",
    "person_1['iat'] = person_1['timestamp_ms'].diff().fillna(0)\n",
    "\n",
    "# normalize iat per bucket\n",
    "person_1['iat_norm'] = person_1.groupby('appearance_bucket')['iat'].transform(\n",
    "    lambda x: (x + 1e-3) / (x.sum() + 1e-6)\n",
    ")\n",
    "\n",
    "person_1 = person_1.groupby('appearance_bucket').filter(lambda g: g['signal'].sum() > 10)\n",
    "\n",
    "# sample person_1 to prioritize sparser samples\n",
    "STRATIFIED_SAMPLE_K = 100\n",
    "\n",
    "person_1 = (\n",
    "    person_1\n",
    "    .sort_values('iat_norm', ascending=False)\n",
    "    .groupby('appearance_bucket')\n",
    "    .head(STRATIFIED_SAMPLE_K)\n",
    "    .sort_values('video_frame_index')\n",
    ")\n",
    "person_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# higher energy = more change\n",
    "# this is like a non-parametric version of KL divergence\n",
    "# we could also do a gaussian KDE and then measure residuals but this requires no\n",
    "# model training >:)\n",
    "\n",
    "def energy_distance_cosine(X: np.ndarray, Y: np.ndarray):\n",
    "    N, M = len(X), len(Y)\n",
    "    cross = np.sum(cdist(X, Y, metric=\"cosine\")) / (N * M)\n",
    "    xx = np.sum(cdist(X, X, metric=\"cosine\")) / (N * N)\n",
    "    yy = np.sum(cdist(Y, Y, metric='cosine')) / (M * M)\n",
    "    return 2 * cross - xx - yy\n",
    "\n",
    "person_1['clip_pca_50'] = PCA(n_components=50).fit_transform(person_1['clip_embedding'].to_list()).tolist()\n",
    "\n",
    "appearance_buckets = []\n",
    "appearance_matrices = []\n",
    "distances = [0]\n",
    "\n",
    "for appearance_bucket, dff in person_1.groupby('appearance_bucket'):\n",
    "    appearance_buckets.append(appearance_bucket)\n",
    "    appearance_matrices.append(np.stack(dff['clip_pca_50'].to_list()))\n",
    "\n",
    "for i in range(1, len(appearance_buckets)):\n",
    "    curr = appearance_matrices[i]\n",
    "    prev = appearance_matrices[i-1]\n",
    "    distances.append(energy_distance_cosine(curr, prev))\n",
    "\n",
    "print([i.size for i in appearance_matrices])\n",
    "print(len(appearance_buckets), len(distances))\n",
    "print([float(round(i, 3)) for i in distances])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.48\n",
    "\n",
    "anomalies = {b: bool(distance > THRESHOLD) for b, distance in zip(appearance_buckets, distances)}\n",
    "person_1['is_anomaly'] = person_1['appearance_bucket'].map(anomalies)\n",
    "print(anomalies)\n",
    "person_1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
